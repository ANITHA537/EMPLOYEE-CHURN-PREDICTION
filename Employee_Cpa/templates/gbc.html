<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css"/>
    <link rel="stylesheet" href="static\styles.css" />
   
  
  <link rel="shortcut icon" href="C:/Users/ANITHA/Desktop/Project/Employee_Cpa/file.jpg" type="image/x-icon">
    <style>
    .centered {
    position: absolute;
    top: 50%;
    left: 25%;
    transform: translate(-50%, -50%); 
    }
    .top-left {
    position: absolute;
    top: 15%;
    }
    .tl {
    position: absolute;
    top: 25%;
    left: 10%;
    }
    ul, ul.points {
                list-style: circle;
                list-style-position: initial;
                list-style-image: initial;
                list-style-type: circle;
                line-height: 150%;
    }
    ::marker {
    unicode-bidi: isolate;
    font-variant-numeric: tabular-nums;
    text-transform: none;
    text-indent: 0px !important;
    text-align: start !important;
    text-align-last: start !important;
}
</style>
  
    <title>EMPLOYEE CHURN PREDICTION</title>
  </head>
  <body>
    <div class="menu-bar">
      <h1 class="logo"><span> EMPLOYEE CHURN</span> PREDICTION </h1>
      <ul>
        <li><a href="Nav">Home</a></li>
        <li><a href="attributes">Required Attributes</a></li>
        <li><a href="index">Upload File Here</a></li>
        <li><a href="about">About</a></li>
      </ul>
    </div>
    <div>
      <div class="container">
        <img src="static\images\background7.jpg" height="100%" width="100%"/>
        <div class="top-left">
            <h2>GRADIENT BOOSTING CLASSIFIER in Machine Learning:</h2>
            <br/>
            <p>Gradient Boosting Machine (GBM) is one of the most popular forward learning ensemble methods in machine learning. It is a powerful technique for building predictive models for regression and classification tasks.</p><br/>
            <p>GBM helps us to get a predictive model in form of an ensemble of weak prediction models such as decision trees. Whenever a decision tree performs as a weak learner then the resulting algorithm is called gradient-boosted trees.</p><br/>
            <p>It enables us to combine the predictions from various learner models and build a final predictive model having the correct prediction.</p><br/>
            <p>But here one question may arise if we are applying the same algorithm then how multiple decision trees can give better predictions than a single decision tree? Moreover, how does each decision tree capture different information from the same data?</p>
            <img src="https://static.javatpoint.com/tutorial/machine-learning/images/gbm-in-machine-learning3.png">
            <p>So, the answer to these questions is that a different subset of features is taken by the nodes of each decision tree to select the best split. It means, that each tree behaves differently, and hence captures different signals from the same data.</p>
        </div>
      </div>
  </body>
</html>